{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "from Dictionary import Dictionary\n",
    "from Discriminator import Discriminator\n",
    "from TrainModel import TrainModel\n",
    "from Evaluator import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default & settings\n",
    "useGPU = True\n",
    "n_epoch_adv = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(source_embedding_path, target_embedding_path, maxCount = 1e10):\n",
    "    #Load embeddings\n",
    "    #read txt embeddings for English(2519370 words with 300 dim) and Chinese(332647 words with 300 dim)\n",
    "    word2id = {}     #e.g. u'\\u5e74 = year\n",
    "    vectors = []\n",
    "    count = 0\n",
    "    with io.open(target_embedding_path, 'r', encoding='utf-8', newline='\\n', errors='ignore') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            #print i,line\n",
    "            #print i\n",
    "\n",
    "            if count>=maxCount:\n",
    "                break\n",
    "            count += 1\n",
    "            if i == 0:\n",
    "                split = line.split()\n",
    "            else:\n",
    "                word, vect = line.rstrip().split(' ', 1) #stripe space from end\n",
    "                #print word #real chars\n",
    "\n",
    "                vect = np.fromstring(vect, sep=' ')\n",
    "\n",
    "                if np.linalg.norm(vect) == 0:  # avoid to have null embeddings\n",
    "                    vect[0] = 0.001 #add a little amount...\n",
    "                \n",
    "                word2id[word] = count-2\n",
    "                vectors.append(vect[None])\n",
    "    \n",
    "#     print len(vectors[0]),word2id\n",
    "    print \"Finished loading\", count, \"words...\"\n",
    "    id2word = {v: k for k, v in word2id.items()}  #reverse of word2id\n",
    "    dic = Dictionary(id2word, word2id, \"zh\")\n",
    "    #print \"len is\",dic.__len__()\n",
    "    embeddings = np.concatenate(vectors, 0)\n",
    "    embeddings = torch.from_numpy(embeddings).float()\n",
    "    return dic, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading 100 words...\n",
      "Finished loading 100 words...\n"
     ]
    }
   ],
   "source": [
    "# load source embedding\n",
    "source_embedding_path = \"data/wiki.en.vec\"\n",
    "target_embedding_path = \"data/wiki.zh.vec\"\n",
    "src_dic, _src_emb = load_embeddings(source_embedding_path,source_embedding_path, 100)\n",
    "src_emb = nn.Embedding(len(src_dic), 300, sparse=True) #dim is set to 300..\n",
    "\n",
    "# load target embedding\n",
    "tgt_dic, _tgt_emb = load_embeddings(target_embedding_path,target_embedding_path, 100)\n",
    "tgt_emb = nn.Embedding(len(tgt_dic), 300, sparse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping\n",
    "mapping = nn.Linear(300, 300, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.1)\n",
       "  (1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "  (2): LeakyReLU(0.2)\n",
       "  (3): Dropout(p=0)\n",
       "  (4): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (5): LeakyReLU(0.2)\n",
       "  (6): Dropout(p=0)\n",
       "  (7): Linear(in_features=2048, out_features=1, bias=True)\n",
       "  (8): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gpu\n",
    "if useGPU:\n",
    "    src_emb.cuda()\n",
    "    tgt_emb.cuda()\n",
    "    mapping.cuda()\n",
    "    discriminator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not normalize embeddings\n",
    "# params.src_mean = normalize_embeddings(src_emb.weight.data, \"\")\n",
    "# params.tgt_mean = normalize_embeddings(tgt_emb.weight.data, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have these four core part cuda: src_emb.cuda(), tgt_emb.cuda(), mapping.cuda(), discriminator.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TrainModel(src_emb, tgt_emb, mapping, discriminator, src_dic, tgt_dic, 'sgd', 0.1)\n",
    "#trainer = TrainModel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Linear.parameters of Linear(in_features=300, out_features=300, bias=False)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dampening': 0,\n",
       "  'lr': 0.1,\n",
       "  'momentum': 0,\n",
       "  'nesterov': False,\n",
       "  'params': [Parameter containing:\n",
       "   -3.6995e-02 -9.0221e-03  3.5143e-02  ...  -4.6831e-02  5.0774e-02 -5.4966e-02\n",
       "    4.2324e-02 -4.2363e-02  1.4072e-02  ...   5.6803e-02 -1.4891e-02  7.0549e-03\n",
       "    4.1286e-02  4.2584e-02 -1.0740e-02  ...  -5.0184e-02  3.4514e-02  1.4231e-02\n",
       "                   ...                   â‹±                   ...                \n",
       "    1.8819e-02 -8.3572e-03 -3.2718e-02  ...   1.6956e-02  1.0110e-02  3.5866e-02\n",
       "   -5.6765e-02  7.4246e-03  4.5668e-02  ...   2.9385e-03  9.0126e-03 -1.9487e-02\n",
       "   -5.5643e-03  1.5083e-02  1.5856e-02  ...  -1.2586e-02  1.7161e-02  3.4722e-02\n",
       "   [torch.cuda.FloatTensor of size 300x300 (GPU 0)]],\n",
       "  'weight_decay': 0}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.map_optimizer.param_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluator initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- ADVERSARIAL TRAINING -------\n",
      "\n",
      "Starting 0 th epoch in adversarial training...\n",
      "{'DIS_COSTS': [0.32523685693740845, 0.3252228796482086, 0.32517892122268677, 0.3252641260623932, 0.325248658657074, 0.32522547245025635, 0.32519593834877014, 0.3251835107803345, 0.3251747488975525, 0.3252125382423401, 0.32525038719177246, 0.32523757219314575, 0.32518646121025085, 0.32520821690559387, 0.3252050280570984, 0.3252267837524414, 0.32522672414779663, 0.3252527713775635, 0.325233519077301, 0.3252032399177551, 0.3252009153366089, 0.3251890540122986, 0.32521581649780273, 0.32522889971733093, 0.3252912759780884, 0.32517626881599426, 0.3252330422401428, 0.3252061903476715, 0.3252313733100891, 0.32520920038223267, 0.32524776458740234, 0.32521766424179077, 0.325209379196167, 0.3252562880516052, 0.32526224851608276, 0.3252134919166565, 0.3253023624420166, 0.32526567578315735, 0.32522356510162354, 0.3252587914466858, 0.32521140575408936, 0.3252250552177429, 0.3251720070838928, 0.3253156244754791, 0.32522717118263245, 0.3252178132534027, 0.32522815465927124, 0.3251810669898987, 0.32520896196365356, 0.3252101540565491, 0.3252069354057312, 0.325255811214447, 0.32518455386161804, 0.32520490884780884, 0.325208455324173, 0.3252031207084656, 0.32518333196640015, 0.3252110779285431, 0.32523709535598755, 0.325201153755188, 0.32523730397224426, 0.32521820068359375, 0.3251967430114746, 0.3251783847808838, 0.32521069049835205, 0.3252408504486084, 0.3252331018447876, 0.32522085309028625, 0.3252470791339874, 0.32522472739219666, 0.32528650760650635, 0.32521164417266846, 0.32519644498825073, 0.3251960873603821, 0.32524943351745605, 0.3251853585243225, 0.32525187730789185, 0.32519978284835815, 0.3252522349357605, 0.32519692182540894, 0.3252049684524536, 0.32523152232170105, 0.3252185583114624, 0.3252648413181305, 0.32522860169410706, 0.3252730667591095, 0.32522132992744446, 0.325195848941803, 0.3252202272415161, 0.32525476813316345, 0.32521533966064453, 0.3252270221710205, 0.3251950442790985, 0.32522648572921753, 0.32521456480026245, 0.32521575689315796, 0.325227290391922, 0.32520049810409546, 0.32519927620887756, 0.325248122215271, 0.3251953125, 0.32521283626556396, 0.3251911997795105, 0.3252299427986145, 0.3252369463443756, 0.32531455159187317, 0.32522544264793396, 0.3251956105232239, 0.3251928687095642, 0.32520365715026855, 0.3252338767051697, 0.32520389556884766, 0.3252055048942566, 0.3252277970314026, 0.32524922490119934, 0.32521212100982666, 0.3252405524253845, 0.32532840967178345, 0.3252963423728943, 0.3253070116043091, 0.325217068195343, 0.325198233127594, 0.3251987099647522, 0.325244277715683, 0.3252412676811218, 0.32519692182540894, 0.32529011368751526, 0.32523274421691895, 0.3251922130584717, 0.3252827823162079, 0.3252275288105011, 0.3252030611038208, 0.3252008557319641, 0.3252567648887634, 0.3252175450325012, 0.32529544830322266, 0.32520604133605957, 0.325217604637146, 0.32526683807373047, 0.3252145051956177, 0.3252139687538147, 0.32519328594207764, 0.325214684009552, 0.32524675130844116, 0.3251834511756897, 0.3252311944961548, 0.32522448897361755, 0.32519859075546265, 0.3252541422843933, 0.3252039849758148, 0.3251993656158447, 0.3251956105232239, 0.32522135972976685, 0.3252239227294922, 0.3251882493495941, 0.3252507150173187, 0.32520368695259094, 0.3252047896385193, 0.3252331614494324, 0.32517457008361816]}\n",
      "Starting 1 th epoch in adversarial training...\n",
      "{'DIS_COSTS': [0.3252074122428894, 0.32522737979888916, 0.32519209384918213, 0.3252038359642029, 0.32524093985557556, 0.32520592212677, 0.32527753710746765, 0.3252045512199402, 0.32523852586746216, 0.3252028226852417, 0.3252372741699219, 0.3252211809158325, 0.32527244091033936, 0.32521307468414307, 0.3252161145210266, 0.3252471685409546, 0.3251815438270569, 0.3252464234828949, 0.32521703839302063, 0.325252890586853, 0.32521772384643555, 0.32524630427360535, 0.3252127766609192, 0.32524311542510986, 0.32523006200790405, 0.32518094778060913, 0.32524484395980835, 0.3252270221710205, 0.32520201802253723, 0.3251919746398926, 0.3252422511577606, 0.32520222663879395, 0.32520413398742676, 0.32520005106925964, 0.32519397139549255, 0.3252084255218506, 0.3252282738685608, 0.3252221941947937, 0.32519593834877014, 0.3252330422401428, 0.32532501220703125, 0.32519128918647766, 0.3252044916152954, 0.3252566456794739, 0.32523292303085327, 0.3252360224723816, 0.3251909911632538, 0.32522597908973694, 0.3251851499080658, 0.32524043321609497, 0.3252224922180176, 0.32518768310546875, 0.325251042842865, 0.3251950740814209, 0.32523995637893677, 0.3251911401748657, 0.3252491056919098, 0.3252484202384949, 0.3252018988132477, 0.3252562880516052, 0.3252262473106384, 0.3251977562904358, 0.32519370317459106, 0.3252578377723694, 0.32519543170928955, 0.3252207040786743, 0.32526835799217224, 0.32518237829208374, 0.32518747448921204, 0.3252287805080414, 0.3252803385257721, 0.32519468665122986, 0.3251991271972656, 0.3252202272415161, 0.3252114951610565, 0.3252522349357605, 0.32525065541267395, 0.3252161741256714, 0.3252317011356354, 0.325200617313385, 0.3252197504043579, 0.3252105116844177, 0.32520270347595215, 0.3252338469028473, 0.32521408796310425, 0.3252256512641907, 0.32518789172172546, 0.32520735263824463, 0.32525062561035156, 0.32521459460258484, 0.3252183496952057, 0.3252317011356354, 0.32520440220832825, 0.32518380880355835, 0.3252505660057068, 0.32524800300598145, 0.32525765895843506, 0.3252026438713074, 0.32522109150886536, 0.325217604637146, 0.32529622316360474, 0.3252151608467102, 0.32520395517349243, 0.3251953423023224, 0.32521796226501465, 0.3252094089984894, 0.3252332806587219, 0.32523930072784424, 0.32527467608451843, 0.32526734471321106, 0.3252560496330261, 0.3252500295639038, 0.32518893480300903, 0.32524192333221436, 0.3252717852592468, 0.32517939805984497, 0.3252505958080292, 0.3252468407154083, 0.325274795293808, 0.32527390122413635, 0.32525497674942017, 0.32519716024398804, 0.32525330781936646, 0.32521578669548035, 0.3251878023147583, 0.32526546716690063, 0.3252078890800476, 0.32528001070022583, 0.325201153755188, 0.3251968026161194, 0.32517537474632263, 0.3252268433570862, 0.3252047896385193, 0.3252261281013489, 0.3252294063568115, 0.3252045214176178, 0.3252353072166443, 0.3252227306365967, 0.32519418001174927, 0.3251732885837555, 0.32521045207977295, 0.32526254653930664, 0.32523131370544434, 0.3252754807472229, 0.325234055519104, 0.3252221345901489, 0.3251652419567108, 0.3252162039279938, 0.3251921534538269, 0.3252147436141968, 0.3252299129962921, 0.3252474367618561, 0.3252480626106262, 0.3252008855342865, 0.3252395987510681, 0.3252314329147339, 0.32521581649780273, 0.3252621591091156, 0.3252083957195282, 0.3251993656158447]}\n",
      "Starting 2 th epoch in adversarial training...\n",
      "{'DIS_COSTS': [0.3253071904182434, 0.3252620995044708, 0.3252314329147339, 0.3253069818019867, 0.3252526521682739, 0.3252282738685608, 0.32524052262306213, 0.32525819540023804, 0.3252054452896118, 0.3252795934677124, 0.3252105116844177, 0.3252115249633789, 0.3251914978027344, 0.32518965005874634, 0.32520073652267456, 0.32524973154067993, 0.32523512840270996, 0.32521259784698486, 0.32520800828933716, 0.3252358138561249, 0.32526397705078125, 0.32521170377731323, 0.3251999616622925, 0.32522493600845337, 0.3252311050891876, 0.3252025842666626, 0.32521718740463257, 0.3252352476119995, 0.32524964213371277, 0.3252464830875397, 0.32522663474082947, 0.32520997524261475, 0.325234591960907, 0.3252047002315521, 0.3252060115337372, 0.32522186636924744, 0.32519209384918213, 0.32522088289260864, 0.32523366808891296, 0.32520779967308044, 0.3252483606338501, 0.32525545358657837, 0.32520610094070435, 0.3252187967300415, 0.32519257068634033, 0.32521724700927734, 0.32524174451828003, 0.3252379298210144, 0.3252612352371216, 0.3252372741699219, 0.32523566484451294, 0.3252533972263336, 0.3252820074558258, 0.3251879811286926, 0.32524579763412476, 0.3252609968185425, 0.3252508044242859, 0.3252185583114624, 0.32525116205215454, 0.3252512216567993, 0.32522398233413696, 0.3252503275871277, 0.325264036655426, 0.32527273893356323, 0.32520705461502075, 0.3252317011356354, 0.32519423961639404, 0.3252221643924713, 0.3252347707748413, 0.32526782155036926, 0.3252430856227875, 0.32522720098495483, 0.3252180218696594, 0.3252202272415161, 0.32520967721939087, 0.3252098560333252, 0.32519930601119995, 0.32524341344833374, 0.3252432346343994, 0.3252051770687103, 0.3252304196357727, 0.32519689202308655, 0.325203537940979, 0.32522571086883545, 0.3252256512641907, 0.3252145051956177, 0.3252393305301666, 0.32519087195396423, 0.32521766424179077, 0.32522711157798767, 0.32519084215164185, 0.32521143555641174, 0.32520678639411926, 0.325312077999115, 0.3252071738243103, 0.3252011835575104, 0.325253427028656, 0.32526618242263794, 0.32522329688072205, 0.325217604637146, 0.32522088289260864, 0.32518815994262695, 0.3253052830696106, 0.325219988822937, 0.32530665397644043, 0.3251718282699585, 0.3251875638961792, 0.3251968026161194, 0.3252285122871399, 0.3252565264701843, 0.3251897990703583, 0.3251887559890747, 0.325248122215271, 0.3252023458480835, 0.3251965045928955, 0.3252277970314026, 0.3252553641796112, 0.32526537775993347, 0.32526248693466187, 0.3252207338809967, 0.3252050578594208, 0.32519465684890747, 0.32526981830596924, 0.32525599002838135, 0.3251988887786865, 0.32520031929016113, 0.32525116205215454, 0.3252367377281189, 0.32519644498825073, 0.32524335384368896, 0.3251974284648895, 0.3252175748348236, 0.3252362608909607, 0.3252682089805603, 0.3252222239971161, 0.32524046301841736, 0.32518434524536133, 0.32531508803367615, 0.32515978813171387, 0.32525545358657837, 0.32519274950027466, 0.3252526819705963, 0.3252440094947815, 0.3252795934677124, 0.3252020478248596, 0.3252151310443878, 0.32524412870407104, 0.32523614168167114, 0.3252040147781372, 0.3251911997795105, 0.3252343535423279, 0.3251860439777374, 0.32527127861976624, 0.325184166431427, 0.32523030042648315, 0.3251703977584839, 0.3252463936805725, 0.32525211572647095, 0.3252009153366089, 0.32521960139274597]}\n",
      "Starting 3 th epoch in adversarial training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DIS_COSTS': [0.3252421021461487, 0.32517629861831665, 0.32520410418510437, 0.32520902156829834, 0.32521775364875793, 0.3252309560775757, 0.32519781589508057, 0.3252214789390564, 0.3252304792404175, 0.3252553939819336, 0.32523566484451294, 0.32523924112319946, 0.3252105116844177, 0.32519590854644775, 0.32523518800735474, 0.3252221345901489, 0.32520586252212524, 0.3252124488353729, 0.3252161145210266, 0.3252643048763275, 0.32522889971733093, 0.32525092363357544, 0.32516974210739136, 0.32526132464408875, 0.32520920038223267, 0.3252355456352234, 0.3252120614051819, 0.3252214789390564, 0.32522061467170715, 0.32521963119506836, 0.3252031207084656, 0.3252352774143219, 0.3252440094947815, 0.3251942992210388, 0.32525724172592163, 0.3252253830432892, 0.3252583146095276, 0.32516956329345703, 0.32521867752075195, 0.32521840929985046, 0.32521915435791016, 0.32520025968551636, 0.3252279758453369, 0.32522404193878174, 0.32526201009750366, 0.3252737820148468, 0.3252585232257843, 0.3252064287662506, 0.3252108693122864, 0.3252272605895996, 0.3252437114715576, 0.32522428035736084, 0.3252097964286804, 0.325175404548645, 0.3252478837966919, 0.3252302408218384, 0.32520151138305664, 0.3252685070037842, 0.32519397139549255, 0.3252243995666504, 0.3252115845680237, 0.32524585723876953, 0.32524967193603516, 0.3252011835575104, 0.325192391872406, 0.3251965343952179, 0.32521986961364746, 0.3252221941947937, 0.32523882389068604, 0.32521140575408936, 0.3251999020576477, 0.3252149224281311, 0.32523828744888306, 0.32525184750556946, 0.3251788914203644, 0.3251907229423523, 0.3252129554748535, 0.325245201587677, 0.32523447275161743, 0.3251895308494568, 0.32525789737701416, 0.32520437240600586, 0.3252032995223999, 0.32523253560066223, 0.32522454857826233, 0.32522380352020264, 0.3252296447753906, 0.32520025968551636, 0.32519423961639404, 0.3251676559448242, 0.3252282440662384, 0.3251909613609314, 0.32525551319122314, 0.3251884877681732, 0.3252532482147217, 0.32521259784698486, 0.3252149522304535, 0.3251839280128479, 0.32520174980163574, 0.32522067427635193, 0.3252512812614441, 0.3252175748348236, 0.3252028524875641, 0.3252043128013611, 0.3251899480819702, 0.3252672851085663, 0.325284481048584, 0.32524845004081726, 0.3252216577529907, 0.32522764801979065, 0.32526370882987976, 0.32521095871925354, 0.3252456784248352, 0.3252301812171936, 0.32519200444221497, 0.3252137303352356, 0.3252100348472595, 0.3252047896385193, 0.3252813518047333, 0.32521602511405945, 0.32524406909942627, 0.3252403736114502, 0.3252112567424774, 0.3251931965351105, 0.32519885897636414, 0.32521721720695496, 0.3251923620700836, 0.32525014877319336, 0.3252084255218506, 0.3251734972000122, 0.3252526819705963, 0.325202614068985, 0.32523688673973083, 0.3252137303352356, 0.3252098262310028, 0.3251975476741791, 0.3253471851348877, 0.32524406909942627, 0.3251994848251343, 0.32519277930259705, 0.32522082328796387, 0.3252524733543396, 0.325215220451355, 0.32526248693466187, 0.3252260982990265, 0.3251851797103882, 0.3252006769180298, 0.32524192333221436, 0.32523971796035767, 0.32518064975738525, 0.32523661851882935, 0.3252093493938446, 0.325236439704895, 0.3252144157886505, 0.3252153992652893, 0.3252822756767273, 0.3252681493759155, 0.3252291679382324, 0.32526060938835144, 0.325201153755188]}\n",
      "Starting 4 th epoch in adversarial training...\n",
      "{'DIS_COSTS': [0.3252197206020355, 0.32522767782211304, 0.32521700859069824, 0.3251853287220001, 0.32518428564071655, 0.3252217769622803, 0.3252105116844177, 0.3251829445362091, 0.3252526521682739, 0.32518842816352844, 0.32522210478782654, 0.3252269923686981, 0.32519978284835815, 0.3251686990261078, 0.3252503573894501, 0.32520592212677, 0.32517603039741516, 0.32520562410354614, 0.3252038359642029, 0.3251980245113373, 0.32518470287323, 0.32519692182540894, 0.3252207636833191, 0.3252127468585968, 0.3252122402191162, 0.32518261671066284, 0.32522493600845337, 0.32517150044441223, 0.32521364092826843, 0.32521116733551025, 0.32522863149642944, 0.3251931667327881, 0.32520630955696106, 0.32519853115081787, 0.3252040445804596, 0.325218141078949, 0.32528403401374817, 0.32521432638168335, 0.3252112865447998, 0.32521671056747437, 0.32527515292167664, 0.32525044679641724, 0.32520925998687744, 0.3252595067024231, 0.3252226710319519, 0.3252444267272949, 0.3252226710319519, 0.3252108097076416, 0.32517343759536743, 0.32522454857826233, 0.32525426149368286, 0.3252229690551758, 0.3252270817756653, 0.3252051770687103, 0.3251841366291046, 0.32524311542510986, 0.3251971900463104, 0.3252919912338257, 0.32526862621307373, 0.3252648711204529, 0.32520097494125366, 0.3253083825111389, 0.3252720236778259, 0.325219064950943, 0.32519763708114624, 0.32524964213371277, 0.3252873420715332, 0.3252321779727936, 0.3252178430557251, 0.32522833347320557, 0.32523927092552185, 0.32525378465652466, 0.32520896196365356, 0.325189471244812, 0.32515788078308105, 0.3252721428871155, 0.32528889179229736, 0.3252185583114624, 0.32521185278892517, 0.3252117335796356, 0.3252267837524414, 0.32522261142730713, 0.325158953666687, 0.325324684381485, 0.32525700330734253, 0.3252197504043579, 0.3252022862434387, 0.325219988822937, 0.32528865337371826, 0.3252522945404053, 0.3252229392528534, 0.3252325654029846, 0.3252040147781372, 0.32523244619369507, 0.32526838779449463, 0.32522115111351013, 0.3252171277999878, 0.32517915964126587, 0.325230211019516, 0.3252374529838562, 0.32524794340133667, 0.3252209424972534, 0.3251761198043823, 0.32525256276130676, 0.32519596815109253, 0.32517072558403015, 0.32518714666366577, 0.3252268135547638, 0.32521337270736694, 0.32522398233413696, 0.32520967721939087, 0.32525908946990967, 0.32517504692077637, 0.32518383860588074, 0.32520249485969543, 0.32524368166923523, 0.325283944606781, 0.3252059519290924, 0.32522261142730713, 0.32526060938835144, 0.3251813054084778, 0.3252218961715698, 0.325236976146698, 0.32521647214889526, 0.32524365186691284, 0.3252265453338623, 0.3251897692680359, 0.3251849412918091, 0.3252300024032593, 0.32520443201065063, 0.3252168893814087, 0.32525360584259033, 0.32524725794792175, 0.32522299885749817, 0.32523196935653687, 0.32521599531173706, 0.32518142461776733, 0.32517534494400024, 0.32520705461502075, 0.3253011107444763, 0.3252430558204651, 0.32518601417541504, 0.32522475719451904, 0.32519102096557617, 0.3252394199371338, 0.32524949312210083, 0.3251875340938568, 0.3252299427986145, 0.32522815465927124, 0.3252457082271576, 0.3252030313014984, 0.3252561092376709, 0.32523173093795776, 0.32519978284835815, 0.3252318501472473, 0.32527387142181396, 0.32524532079696655, 0.32523059844970703, 0.3251723647117615, 0.325228214263916]}\n"
     ]
    }
   ],
   "source": [
    "#Adversarial Training\n",
    "print('--------- ADVERSARIAL TRAINING -------\\n')\n",
    "#epoch_size = 1000000\n",
    "epoch_size = 1000\n",
    "batch_size = 32\n",
    "dis_steps = 5\n",
    "for epoch in xrange(n_epoch_adv):\n",
    "    print('Starting %i th epoch in adversarial training...' % epoch)\n",
    "    tic = time.time()\n",
    "    n_words_proc = 0\n",
    "    stats = {'DIS_COSTS': []}\n",
    "    for n_iter in range(0, epoch_size, batch_size):\n",
    "        # discriminator training\n",
    "        for _ in range(dis_steps):\n",
    "            trainer.dis_step(stats)\n",
    "    #print stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
